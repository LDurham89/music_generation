{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a858b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "from music21 import converter, instrument, note, chord\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM,SimpleRNN, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141cdf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install music21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3094a0e",
   "metadata": {},
   "source": [
    "#### Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d7ad1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\Music generation project\"\n",
    "\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06680de8",
   "metadata": {},
   "source": [
    "#### Read in the midi files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = []\n",
    "folder = Path(\"D:\\\\Music generation project\\\\Data\\\\maestro-v3.0.0\")\n",
    "for file in folder.rglob('*.midi'):\n",
    "  songs.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_songs= songs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will need to check indentation structure and see if i've told this to do the right things, is the entire append activity only under the 'else' clause?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "notes = []\n",
    "for i,file in enumerate(songs):\n",
    "    print(f'{i+1}: {file}')\n",
    "    try:\n",
    "      midi = converter.parse(file)\n",
    "      notes_to_parse = None\n",
    "      parts = instrument.partitionByInstrument(midi)\n",
    "      if parts: # file has instrument parts\n",
    "          notes_to_parse = parts.parts[0].recurse()\n",
    "      else: # file has notes in a flat structure\n",
    "          notes_to_parse = midi.flat.notes      \n",
    "      for element in notes_to_parse:\n",
    "           if isinstance(element, note.Note):\n",
    "              notes.append(str(element.pitch))\n",
    "           elif isinstance(element, chord.Chord):\n",
    "              notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    except:\n",
    "      print(f'FAILED: {i+1}: {file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6086db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e7386b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c01d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('music_notes.pkl', 'wb') as f:\n",
    "  pickle.dump(notes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec75ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb84a2a3",
   "metadata": {},
   "source": [
    "#### load data for new session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61d1c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('music_notes.pkl', 'rb') as f:\n",
    "\n",
    "    notes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e0abb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cca1e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef prepare_sequences(notes, n_vocab):\\n    #Prepare the sequences used by the Neural Network\\n    sequence_length = 32\\n\\n    # Get all unique pitchnames\\n    pitchnames = sorted(set(item for item in notes))\\n    numPitches = len(pitchnames)\\n\\n     # Create a dictionary to map pitches to integers\\n    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\\n\\n    network_input = []\\n    network_output = []\\n\\n    # create input sequences and the corresponding outputs\\n    for i in range(0, len(notes) - sequence_length, 1):\\n        # sequence_in is a sequence_length list containing sequence_length notes\\n        sequence_in = notes[i:i + sequence_length] # LD - DON'T RALLY GET WHAT i:i MEANS\\n        # sequence_out is the sequence_length + 1 note that comes after all the notes in\\n        # sequence_in. This is so the model can read sequence_length notes before predicting\\n        # the next one.\\n        sequence_out = notes[i + sequence_length]\\n        # network_input is the same as sequence_in but it containes the indexes from the notes\\n        # because the model is only fed the indexes.\\n        network_input.append([note_to_int[char] for char in sequence_in])\\n        # network_output containes the index of the sequence_out\\n        network_output.append(note_to_int[sequence_out])\\n\\n    # n_patters is the length of the times it was iterated \\n    # for example if i = 3, then n_patterns = 3\\n    # because network_input is a list of lists\\n    n_patterns = len(network_input)\\n\\n    # reshape the input into a format compatible with LSTM layers\\n    # Reshapes it into a n_patterns by sequence_length matrix\\n    print(len(network_input))\\n    \\n    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\\n    # normalize input\\n    network_input = network_input / float(n_vocab)\\n\\n    # OneHot encodes the network_output\\n    network_output = to_categorical(network_output, numPitches)\\n\\n    return (network_input, network_output)\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    #Prepare the sequences used by the Neural Network\n",
    "    sequence_length = 32\n",
    "\n",
    "    # Get all unique pitchnames\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    numPitches = len(pitchnames)\n",
    "\n",
    "     # Create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        # sequence_in is a sequence_length list containing sequence_length notes\n",
    "        sequence_in = notes[i:i + sequence_length] # LD - DON'T RALLY GET WHAT i:i MEANS\n",
    "        # sequence_out is the sequence_length + 1 note that comes after all the notes in\n",
    "        # sequence_in. This is so the model can read sequence_length notes before predicting\n",
    "        # the next one.\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        # network_input is the same as sequence_in but it containes the indexes from the notes\n",
    "        # because the model is only fed the indexes.\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        # network_output containes the index of the sequence_out\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    # n_patters is the length of the times it was iterated \n",
    "    # for example if i = 3, then n_patterns = 3\n",
    "    # because network_input is a list of lists\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    # Reshapes it into a n_patterns by sequence_length matrix\n",
    "    print(len(network_input))\n",
    "    \n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    # OneHot encodes the network_output\n",
    "    network_output = to_categorical(network_output, numPitches)\n",
    "\n",
    "    return (network_input, network_output)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927debf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_vocab = len(set(notes))\n",
    "#network_input, network_output = prepare_sequences(notes,n_vocab)\n",
    "#n_patterns = len(network_input)\n",
    "#pitchnames = sorted(set(item for item in notes))\n",
    "#numPitches = len(pitchnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cae608f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef prepare_sequences(notes, n_vocab, sequence_length=32, batch_size=128):\\n    #Prepare sequences used by the Neural Network \\n    pitchnames = sorted(set(notes))\\n    num_pitches = len(pitchnames)\\n    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\\n\\n    def generator():\\n        for i in range(0, len(notes) - sequence_length, batch_size):\\n            batch_input = []\\n            batch_output = []\\n            for j in range(batch_size):\\n                if i + j + sequence_length < len(notes):\\n                 sequence_in = notes[i + j:i + j + sequence_length]\\n                 sequence_out = notes[i + j + sequence_length]\\n                 batch_input.append([note_to_int[char] for char in sequence_in])\\n                 batch_output.append(note_to_int[sequence_out])\\n                yield np.array(batch_input), to_categorical(batch_output, num_pitches)\\n                \\n            else:\\n                pass \\n\\n    return generator()\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First go\n",
    "\"\"\"\n",
    "def prepare_sequences(notes, n_vocab, sequence_length=32, batch_size=128):\n",
    "    #Prepare sequences used by the Neural Network \n",
    "    pitchnames = sorted(set(notes))\n",
    "    num_pitches = len(pitchnames)\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    def generator():\n",
    "        for i in range(0, len(notes) - sequence_length, batch_size):\n",
    "            batch_input = []\n",
    "            batch_output = []\n",
    "            for j in range(batch_size):\n",
    "                if i + j + sequence_length < len(notes):\n",
    "                 sequence_in = notes[i + j:i + j + sequence_length]\n",
    "                 sequence_out = notes[i + j + sequence_length]\n",
    "                 batch_input.append([note_to_int[char] for char in sequence_in])\n",
    "                 batch_output.append(note_to_int[sequence_out])\n",
    "                yield np.array(batch_input), to_categorical(batch_output, num_pitches)\n",
    "                \n",
    "            else:\n",
    "                pass \n",
    "\n",
    "    return generator()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f1713fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second go\n",
    "\n",
    "def generator():\n",
    "    try:\n",
    "        for i in range(0, len(notes) - sequence_length, batch_size):\n",
    "            batch_input = []\n",
    "            batch_output = []\n",
    "            for j in range(batch_size):\n",
    "                if i + j + sequence_length < len(notes):\n",
    "                    sequence_in = notes[i + j:i + j + sequence_length]\n",
    "                    sequence_out = notes[i + j + sequence_length]\n",
    "                    batch_input.append([note_to_int[char] for char in sequence_in])\n",
    "                    batch_output.append(note_to_int[sequence_out])\n",
    "            yield np.array(batch_input), to_categorical(batch_output, num_pitches)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred in the generator:\", e)\n",
    "        # Optionally, you can handle the error further or raise it again to propagate it\n",
    "\n",
    "# Create and return an instance of the generator\n",
    "    return generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c345f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage:\n",
    "n_vocab = len(set(notes))\n",
    "sequence_generator = prepare_sequences(notes, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa5775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51d50931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object prepare_sequences.<locals>.generator at 0x0000023D00070EB0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb8ca2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c03642b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a callback to save weight when the loss function declines\n",
    "num_epochs = 10\n",
    "\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger_1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss', \n",
    "    verbose=1,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#history = model.fit(networkInputShaped, networkOutputShaped, epochs=num_epochs, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cad12235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28821/28821 [==============================] - ETA: 0s - loss: 3.7756\n",
      "Epoch 1: loss improved from inf to 3.77560, saving model to weights-improvement-01-3.7756-bigger_1.hdf5\n",
      "28821/28821 [==============================] - 2473s 86ms/step - loss: 3.7756\n",
      "Epoch 2/10\n",
      "28821/28821 [==============================] - ETA: 0s - loss: 3.8623\n",
      "Epoch 2: loss did not improve from 3.77560\n",
      "28821/28821 [==============================] - 2400s 83ms/step - loss: 3.8623\n",
      "Epoch 3/10\n",
      "28821/28821 [==============================] - ETA: 0s - loss: 3.9264\n",
      "Epoch 3: loss did not improve from 3.77560\n",
      "28821/28821 [==============================] - 2343s 81ms/step - loss: 3.9264\n",
      "Epoch 4/10\n",
      "28821/28821 [==============================] - ETA: 0s - loss: 3.9170\n",
      "Epoch 4: loss did not improve from 3.77560\n",
      "28821/28821 [==============================] - 2277s 79ms/step - loss: 3.9170\n",
      "Epoch 5/10\n",
      "28821/28821 [==============================] - ETA: 0s - loss: 3.7799\n",
      "Epoch 5: loss did not improve from 3.77560\n",
      "28821/28821 [==============================] - 2740s 95ms/step - loss: 3.7799\n",
      "Epoch 6/10\n",
      "28821/28821 [==============================] - ETA: 0s - loss: 3.8402\n",
      "Epoch 6: loss did not improve from 3.77560\n",
      "28821/28821 [==============================] - 2394s 83ms/step - loss: 3.8402\n",
      "Epoch 7/10\n",
      "28820/28821 [============================>.] - ETA: 0s - loss: 3.9211\n",
      "Epoch 7: loss did not improve from 3.77560\n",
      "28821/28821 [==============================] - 2286s 79ms/step - loss: 3.9211\n",
      "Epoch 8/10\n",
      "28821/28821 [==============================] - ETA: 0s - loss: 4.0646\n",
      "Epoch 8: loss did not improve from 3.77560\n",
      "28821/28821 [==============================] - 2340s 81ms/step - loss: 4.0646\n",
      "Epoch 9/10\n",
      "28821/28821 [==============================] - ETA: 0s - loss: 3.8988\n",
      "Epoch 9: loss did not improve from 3.77560\n",
      "28821/28821 [==============================] - 2369s 82ms/step - loss: 3.8988\n",
      "Epoch 10/10\n",
      "28821/28821 [==============================] - ETA: 0s - loss: 4.0296\n",
      "Epoch 10: loss did not improve from 3.77560\n",
      "28821/28821 [==============================] - 2384s 83ms/step - loss: 4.0296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d0eef9f40>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(32, 1)))\n",
    "model.add(Dense(n_vocab, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train the model using the generator function\n",
    "model.fit(sequence_generator, steps_per_epoch=len(notes)//128, epochs=10, callbacks=callbacks_list) #128 is batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577e5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028716c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da6684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is quite a badly defined model, no activation function in may of these, no model.fit, etc\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(\n",
    "    512,\n",
    "    input_shape=(32, 1),\n",
    "    return_sequences=True\n",
    "))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(256))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dense(256))\n",
    "model.add(LSTM(512))\n",
    "#model.add(Dense(numPitches))\n",
    "model.add(Dense(numPitches))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T APPEAR TO HAVE ANY MODEL.FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4bd5f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input_length = sum(1 for _ in sequence_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19051ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689216\n"
     ]
    }
   ],
   "source": [
    "print(network_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1104916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d53becfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#V1\n",
    "\"\"\"\n",
    "\n",
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "   #Generate notes from the neural network based on a sequence of notes \n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    # Selects a random row from the network_input\n",
    "    network_input_length = sum(1 for _ in network_input)\n",
    "    \n",
    "    #start = np.random.randint(0, len(network_input_length)-1)\n",
    "    start = np.random.randint(0, network_input_length - 1)\n",
    "    print(f'start: {start}')\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    # Random row from network_input\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        # Reshapes pattern into a vector\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        # Standarizes pattern\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        # Predicts the next note\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        # Outputs a OneHot encoded vector, so this picks the columns\n",
    "        # with the highest probability\n",
    "        index = np.argmax(prediction)\n",
    "        # Maps the note to its respective index\n",
    "        result = int_to_note[index]\n",
    "        # Appends the note to the prediction_output\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        # Adds the predicted note to the pattern\n",
    "        pattern = np.append(pattern,result)\n",
    "        # Slices the array so that it contains the predicted note\n",
    "        # eliminating the first from the array, so the model can\n",
    "        # have a sequence\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f99fc243",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_generator = prepare_sequences(notes, n_vocab)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1b4185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2\n",
    "\n",
    "def generate_notes(model, network_input_generator, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Count the number of elements in the generator without consuming it\n",
    "    network_input_length = sum(1 for _ in network_input_generator)\n",
    "\n",
    "    # Reset the generator to its initial state\n",
    "    #network_input_generator = prepare_sequences(notes, n_vocab)\n",
    "    \n",
    "    # Select a random start index within the valid range\n",
    "    start = np.random.randint(0, network_input_length - 1)\n",
    "    print(f'start: {start}')\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    # Random row from network_input\n",
    "    for i, (batch_input, _) in enumerate(network_input_generator):\n",
    "        if i == start:\n",
    "            pattern = batch_input\n",
    "            break\n",
    "\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        # Reshapes pattern into a vector\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        # Standarizes pattern\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        # Predicts the next note\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        # Outputs a OneHot encoded vector, so this picks the columns\n",
    "        # with the highest probability\n",
    "        index = np.argmax(prediction)\n",
    "        # Maps the note to its respective index\n",
    "        result = int_to_note[index]\n",
    "        # Appends the note to the prediction_output\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        # Adds the predicted note to the pattern\n",
    "        pattern = np.append(pattern, index)\n",
    "        # Slices the array so that it contains the predicted note\n",
    "        # eliminating the first from the array, so the model can\n",
    "        # have a sequence\n",
    "        pattern = pattern[1:]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8d497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "10d52a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input_generator, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Count the number of elements in the generator without consuming it\n",
    "    network_input_length = sum(1 for _ in network_input_generator)\n",
    "\n",
    "    # Reset the generator to its initial state - does this line need commenting out?\n",
    "    network_input_generator = prepare_sequences(notes, n_vocab)\n",
    "    \n",
    "    # Select a random start index within the valid range\n",
    "    start = np.random.randint(0, network_input_length - 1)\n",
    "    print(f'start: {start}')\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    # Initialize pattern with a default value\n",
    "    pattern = None\n",
    "\n",
    "    # Random row from network_input\n",
    "    for i, (batch_input, _) in enumerate(network_input_generator):\n",
    "        if i == start:\n",
    "            pattern = batch_input\n",
    "            break\n",
    "\n",
    "    # Check if pattern is still None (i.e., network_input_generator is empty)\n",
    "    if pattern is None:\n",
    "        raise ValueError(\"Network input generator is empty. Please check your input data.\")\n",
    "\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        # Reshapes pattern into a vector\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        # Standardizes pattern\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        # Predicts the next note\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        # Outputs a OneHot encoded vector, so this picks the columns\n",
    "        # with the highest probability\n",
    "        index = np.argmax(prediction)\n",
    "        # Maps the note to its respective index\n",
    "        result = int_to_note[index]\n",
    "        # Appends the note to the prediction_output\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        # Adds the predicted note to the pattern\n",
    "        pattern = np.append(pattern, index)\n",
    "        # Slices the array so that it contains the predicted note\n",
    "        # eliminating the first from the array, so the model can\n",
    "        # have a sequence\n",
    "        pattern = pattern[1:]\n",
    "\n",
    "    return prediction_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "485e00a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 3355299\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1152 into shape (1,36,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m n_vocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(notes))\n\u001b[0;32m      2\u001b[0m pitchnames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m notes))\n\u001b[1;32m----> 3\u001b[0m prediction_output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_notes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpitchnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_vocab\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [74]\u001b[0m, in \u001b[0;36mgenerate_notes\u001b[1;34m(model, network_input_generator, pitchnames, n_vocab)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# generate 500 notes\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m note_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Reshapes pattern into a vector\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     prediction_input \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Standardizes pattern\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     prediction_input \u001b[38;5;241m=\u001b[39m prediction_input \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(n_vocab)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1152 into shape (1,36,1)"
     ]
    }
   ],
   "source": [
    "n_vocab = len(set(notes))\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "prediction_output = generate_notes(model, sequence_generator, pitchnames, n_vocab)\n",
    "\n",
    "# 'network_input' should be sequence generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef69fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1942212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
